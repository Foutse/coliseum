{
  "metadata" : {
    "name" : "Mean-Shift-LSH",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "${HOME}/.ivy2",
    "customRepos" : null,
    "customDeps" : [ "spartakus %% neirest-neighbours-mean-shift-lsh % 1.0", "org.apache.sanselan % sanselan % 0.97-incubator" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : {
      "spark.executor.memory" : "1024m",
      "spark.cassandra.connection.host" : "127.0.0.1",
      "spark.cores.max" : "2",
      "spark.executor.cores" : "2",
      "spark.master" : "local[*]"
    }
  },
  "cells" : [ {
    "metadata" : {
      "id" : "665E1308508949228ABABA6F0287BCDF"
    },
    "cell_type" : "markdown",
    "source" : "# Mean Shift (with LSH)"
  }, {
    "metadata" : {
      "id" : "40864413B8D34168B2FA7FF90066F6FC"
    },
    "cell_type" : "markdown",
    "source" : "Project: [here](https://github.com/Spark-clustering-notebook/Mean-Shift-LSH)"
  }, {
    "metadata" : {
      "id" : "DE652DD323FF40CE8E4F68F47DF18056"
    },
    "cell_type" : "markdown",
    "source" : "Parameters\n\n* `k` is the number of neighbours to look at in order to compute centroid.\n* `nbseg` is the number of segments on which the data vectors are projected during LSH. Its value should usually be larger than 20, depending on the data set.\n* `nbblocs` is a crucial parameter as larger values give faster but less accurate LSH approximate nearest neighbors, and as smaller values give slower but more accurate approximations.\n* `cmin` is the threshold under which clusters with fewer than cmin members are merged with the next nearest cluster.\n* `normalisation` is a flag if the data should be first normalized $(X-X_{min})/(X_{max}-X_{min})$ before clustering.\n* `w` is a uniformisation constant for LSH.\n* `npPart` is the default parallelism outside the gradient ascent.\n* `yStarIter` is the maximum number of iterations in the gradient ascent in the mean shift update.\n* `threshold_cluster` is the threshold under which two final mean shift iterates are considered to be in the same cluster."
  }, {
    "metadata" : {
      "id" : "D65560046F9348078F2B977ADB1EA284"
    },
    "cell_type" : "markdown",
    "source" : "# Image analysis"
  }, {
    "metadata" : {
      "id" : "ABFE286BC990419686240F2A8CD702B0"
    },
    "cell_type" : "markdown",
    "source" : "To carry out image analysis, it is recommended to convert the usual color formats (e.g. `RGB`, `CYMK`) to the `Luv* color space` as the close values in the Luv-space correspond more to visual perceptions of color proximity, as well adding the row and column indices (x,y). \n\nEach pixel is transformed to a 5-dimensional vector $(x,y,L, u, v)$ which is then input into the mean shift clustering."
  }, {
    "metadata" : {
      "id" : "F8F12109A38B4C328BBA3E1CB3BABEE8"
    },
    "cell_type" : "markdown",
    "source" : "Train on the picture on the [color image #124084](https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300/html/dataset/images/color/124084.html) from [Berkeley Segmentation Dataset and Benchmark repository](https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/).\n\n<img src=\"https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300/html/images/plain/normal/color/124084.jpg\"/>"
  }, {
    "metadata" : {
      "id" : "77E7EBC9FB134B0EB9B045DB846A996E"
    },
    "cell_type" : "markdown",
    "source" : "## Utils"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "181C579361B5487A9A4872AB24C68BC7"
    },
    "cell_type" : "code",
    "source" : "import org.apache.sanselan.color.ColorConversions._",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "BACAFA6383D441B082B381A957BDDC99"
    },
    "cell_type" : "code",
    "source" : "def toLUV(bni:java.awt.image.BufferedImage, x:Int, y:Int) = {\n  //val xyz = org.apache.commons.imaging.color.ColorConversions.convertRGBtoXYZ(bni.getRGB(x,y))\n  val xyz = convertRGBtoXYZ(bni.getRGB(x,y))\n  val luv = convertXYZtoCIELuv(xyz)\n  (x+1, y+1, luv.L, luv.u, luv.v)\n}\ndef toRGB(L:Double, u:Double, v:Double) = {\n  val xyz = convertCIELuvtoXYZ(L, u, v)\n  val rgb = convertXYZtoRGB(xyz)\n  rgb\n}",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "A0F0B604F7994E588B7428FBFA5D7E4E"
    },
    "cell_type" : "markdown",
    "source" : "## Build data <small>(optional)</small>"
  }, {
    "metadata" : {
      "id" : "5E50B2BEBA6C4CB8ABE1D600CCDB0E51"
    },
    "cell_type" : "markdown",
    "source" : "The data has to be given to the model training in _Luv_ colorspace, an usual way to represent the data then is CSV where the columns are $X$, $Y$, $L$, $u$, $v$."
  }, {
    "metadata" : {
      "id" : "0FECA1FB4E994E64890E5992A81692A5"
    },
    "cell_type" : "markdown",
    "source" : "In the current section, we'll take a picture and transform it in CSV in case we don't have it yet..."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "7F35A36C2A1443848C2B7E341BC7FD1A"
    },
    "cell_type" : "code",
    "source" : "val imgpath = \"/root/data/coliseum/124084-orig.jpg\"",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "663D86D7FF164DC7833801D49DDB5820"
    },
    "cell_type" : "code",
    "source" : "val bni = javax.imageio.ImageIO.read(new File(imgpath))",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "D65BF716451D40CF9010B9D3F094C314"
    },
    "cell_type" : "code",
    "source" : "val h = bni.getHeight\nval w = bni.getWidth",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "95DCC9B4242441D687ED7CD609246EB9"
    },
    "cell_type" : "code",
    "source" : "val luvs = for {\n  r <- 0 until h\n  c <- 0 until w\n} yield toLUV(bni, c, r)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "717D6456E89F46F8B62DA04E1A1404FC"
    },
    "cell_type" : "code",
    "source" : "val outputCSV = new File(\"/root/data/coliseum/output/124084-luv.jpg.csv\")\nif (outputCSV.exists) outputCSV.delete",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "D8DBCFFF12EB4A8AB6F98847B19F7E0D"
    },
    "cell_type" : "code",
    "source" : "val writer = new java.io.FileWriter(outputCSV)\nwriter.write(\"\"\" \"x\",\"y\",\"L\",\"u\",\"v\" \"\"\".trim)\nluvs.foreach { case (x, y, l, u, v) =>\n  writer.write(s\"\\n$x,$y,$l,$u,$v\")\n}\nwriter.flush\nwriter.close",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "523552796BF4454B8A7AE0F5B57A440B"
    },
    "cell_type" : "markdown",
    "source" : "## Build Model"
  }, {
    "metadata" : {
      "id" : "FFDBB07BFC5042BAA09BA932F1E1534B"
    },
    "cell_type" : "markdown",
    "source" : "Import model instance from Mean Shift LSH package"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "2CD1660329D3459AA6A1F460F526E8A0"
    },
    "cell_type" : "code",
    "source" : "val defp = sparkContext.defaultParallelism\nval meanShift = msLsh.MsLsh",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "5AC52214318B42E680DDEFCBA80250F2"
    },
    "cell_type" : "markdown",
    "source" : "Read the input data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "2DFED1EC049C4E448242E4DAA554953F"
    },
    "cell_type" : "code",
    "source" : "val data = sc.textFile(\"/root/data/coliseum/124084-luv.csv\", defp)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "5D43FDA739CD4EE6B2E6CE42FAC976D3"
    },
    "cell_type" : "markdown",
    "source" : "Parse the lines, excluding the header and mapping to _mllib_ package"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "FA3F7315EA544FC982FB8ABAB2768B74"
    },
    "cell_type" : "code",
    "source" : "val parsedData = data.filter(!_.startsWith(\"\\\"\")).map(x => x.split(','))\n                     .map(y => org.apache.spark.mllib.linalg.Vectors.dense(y.map(_.toDouble)))\n                     .zipWithIndex.map(_.swap)\n                     .map(x => (x._1.toString, x._2)).cache",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "5F6899541A9E4BFA8D865D1700DB3722"
    },
    "cell_type" : "markdown",
    "source" : "Creating SQL tools to allow DataFrame usage which will ease quick exploration."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "0EDDEECCF3A6430498B5359548AFF624"
    },
    "cell_type" : "code",
    "source" : "val sqlc = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlc.implicits._",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "5D3BB8DAA05A4F78BCBB5D042BC0D0C8"
    },
    "cell_type" : "markdown",
    "source" : "Taking a look to the data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "E77754F4948E418180CDE925893AFF8F"
    },
    "cell_type" : "code",
    "source" : "parsedData.toDF",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "A6F20DD554F64F29B7140896785BD031"
    },
    "cell_type" : "markdown",
    "source" : "### Training the model"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "7DFA71ADF24645BE84F35C312F7FEDF9"
    },
    "cell_type" : "code",
    "source" : "var model:msLsh.mean_shift_lsh_model = null",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "0BCAB11EADA84E689AD820ED34F1318A"
    },
    "cell_type" : "code",
    "source" : "val logTrain = out\nlogTrain",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F03412F67D2F47BF9CA6008D27B5BC7F"
    },
    "cell_type" : "code",
    "source" : "Form[Map[String,String]](\n  d = Map(\n    \"k\" -> \"60\",\n    \"threshold_cluster\" -> \"0.05\",\n    \"yStarIter\" -> \"10\",\n    \"cmin\" -> \"0\",\n    \"normalisation\" -> \"true\",\n    \"w\" -> \"1\",\n    \"nbseg\" -> \"100\",\n    \"nbblocs\" -> \"50\"\n  ), \n  mainTitle = \"Tune the model\", \n  paramsToData = identity[Map[String,String]], \n  dataToParams = identity[Map[String,String]]\n) { map =>\n  logTrain(\"Starting Model Training\")\n  model = meanShift.train(sparkContext,\n                            parsedData,\n                            map(\"k\").toInt,\n                            map(\"threshold_cluster\").toDouble,\n                            map(\"yStarIter\").toInt,\n                            map(\"cmin\").toInt,\n                            map(\"normalisation\").toBoolean,\n                            map(\"w\").toInt,\n                            map(\"nbseg\").toInt,\n                            map(\"nbblocs\").toInt,\n                            nbPart=defp\n                          )\n  logTrain(\"Model trained\")\n}",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "9D93E4989A0C4D6988CB2EC3E119EEB5"
    },
    "cell_type" : "markdown",
    "source" : "Save result for an image as `(ID, Vector, ClusterNumber)`"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "05F298A3A56B4057AA2DC835C10DA548"
    },
    "cell_type" : "code",
    "source" : "val imageResultPath = \"/root/data/coliseum/output/MyImageResultDirectory\"",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "006C9B792A1C45BCBF71787290833C1A"
    },
    "cell_type" : "code",
    "source" : ":sh rm -rf $imageResultPath",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "B7CE2DF0FDA947A484CBD24FF2AA1A22"
    },
    "cell_type" : "code",
    "source" : "// Results look's like RDD[ID,Centroïd_Vector,cluster_Number]\nmeanShift.saveImageAnalysis(model, imageResultPath,1)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "C6AA8685036B4077AAE5B8CE13E0E3CE"
    },
    "cell_type" : "markdown",
    "source" : "Save result as `(ID, ClusterNumber)`"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "9F4361C151AE441A9E58F50698889601"
    },
    "cell_type" : "code",
    "source" : "val resultDirPath = \"/root/data/coliseum/output/MyResultDirectory\"",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "94B903E6D54340158F4790457AD85918"
    },
    "cell_type" : "code",
    "source" : ":sh rm -rf $resultDirPath ",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "811999536B594829A0D8B94633120091"
    },
    "cell_type" : "code",
    "source" : "meanShift.savelabeling(model, resultDirPath, 1)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "1AD12FA2A56F419482773192F8FAB395"
    },
    "cell_type" : "markdown",
    "source" : "Save centroids result as `(NumCluster, cardinality, CentroidVector)`"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "C11E5610C37042418035E3F5ED71A8EA"
    },
    "cell_type" : "code",
    "source" : "val centroidDirPath = \"/root/data/coliseum/output/centroidDirectory\"",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "D5BC944A011748F2BC9C4D45BBDAB437"
    },
    "cell_type" : "code",
    "source" : ":sh rm -rf $centroidDirPath",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "72739559D66142618175FE0579C61CC1"
    },
    "cell_type" : "code",
    "source" : "meanShift.saveClusterInfo(sparkContext, model, centroidDirPath)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "74B7BFA98AB04A93986E3D7EAE2CAACD"
    },
    "cell_type" : "markdown",
    "source" : "# Read Model Info"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "B1530C4E04E64062A86A97D26C8F8C6C"
    },
    "cell_type" : "code",
    "source" : "val resultImage = sparkContext.textFile(imageResultPath)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "F0DC0A6BE8804CBE8965CF3316897322"
    },
    "cell_type" : "code",
    "source" : "val parsed = resultImage.map { s =>\n  val l = s.split(\",\").toList.map(_.replaceAll(\"[\\\\[\\\\]\\\\(\\\\)]\", \"\"))\n  val id = l.head.toInt\n  val centroid = org.apache.spark.mllib.linalg.Vectors.dense(l.tail.init.map(_.toDouble).toArray)\n  val cluster = l.last.toInt\n  (id, centroid, cluster)\n}",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "BAE857AA59F5410881C8068F01AA57C0"
    },
    "cell_type" : "code",
    "source" : "val parsedDf = parsed.toDF",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "F8F0FCD397814AF28F38672606E1D82A"
    },
    "cell_type" : "code",
    "source" : "val resArr = parsedDf.select(\"_2\").map(_.getAs[org.apache.spark.mllib.linalg.Vector](0)).map(_.toArray.toList).collect\nval resList = resArr.toList",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "3C01A0A3F16E42EC93CF94D87DEA3878"
    },
    "cell_type" : "code",
    "source" : "import java.awt.image.BufferedImage\nval resImg = new BufferedImage(h, w, BufferedImage.TYPE_INT_RGB)\nval rbgs:Array[Int] = resArr.map{ case List(_, _, l, u, v) => toRGB(l, u, v) }.toArray\nresImg.setRGB(0, 0, h, w, rbgs, 0, h)\nval ii = img(\"jpg\", h+\"px\", w+\"px\")\nii(resImg)\nii",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}