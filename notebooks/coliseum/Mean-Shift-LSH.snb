{"metadata":{"name":"Mean-Shift-LSH","user_save_timestamp":"1970-01-01T00:00:00.000Z","auto_save_timestamp":"1970-01-01T00:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":"${HOME}/.ivy2","customRepos":["spartakus % default % http://dl.bintray.com/spark-clustering-notebook/maven % maven"],"customDeps":["spartakus %% neirest-neighbours-mean-shift-lsh % 1.0","org.apache.sanselan % sanselan % 0.97-incubator"],"customImports":null,"customArgs":null,"customSparkConf":{"spark.executor.memory":"1024m","spark.cassandra.connection.host":"127.0.0.1","spark.cores.max":"2","spark.executor.cores":"2","spark.master":"local[*]"}},"cells":[{"metadata":{"id":"665E1308508949228ABABA6F0287BCDF"},"cell_type":"markdown","source":"# Mean Shift (with LSH)"},{"metadata":{"id":"40864413B8D34168B2FA7FF90066F6FC"},"cell_type":"markdown","source":"Project: [here](https://github.com/Spark-clustering-notebook/Mean-Shift-LSH)"},{"metadata":{"id":"DE652DD323FF40CE8E4F68F47DF18056"},"cell_type":"markdown","source":"Parameters\n\n* `k` is the number of neighbours to look at in order to compute centroid.\n* `nbseg` is the number of segments on which the data vectors are projected during LSH. Its value should usually be larger than 20, depending on the data set.\n* `nbblocs` is a crucial parameter as larger values give faster but less accurate LSH approximate nearest neighbors, and as smaller values give slower but more accurate approximations.\n* `cmin` is the threshold under which clusters with fewer than cmin members are merged with the next nearest cluster.\n* `normalisation` is a flag if the data should be first normalized $(X-X_{min})/(X_{max}-X_{min})$ before clustering.\n* `w` is a uniformisation constant for LSH.\n* `npPart` is the default parallelism outside the gradient ascent.\n* `yStarIter` is the maximum number of iterations in the gradient ascent in the mean shift update.\n* `threshold_cluster` is the threshold under which two final mean shift iterates are considered to be in the same cluster."},{"metadata":{"id":"D65560046F9348078F2B977ADB1EA284"},"cell_type":"markdown","source":"# Image analysis"},{"metadata":{"id":"ABFE286BC990419686240F2A8CD702B0"},"cell_type":"markdown","source":"To carry out image analysis, it is recommended to convert the usual color formats (e.g. `RGB`, `CYMK`) to the `Luv* color space` as the close values in the Luv-space correspond more to visual perceptions of color proximity, as well adding the row and column indices (x,y). \n\nEach pixel is transformed to a 5-dimensional vector $(x,y,L, u, v)$ which is then input into the mean shift clustering."},{"metadata":{"id":"F8F12109A38B4C328BBA3E1CB3BABEE8"},"cell_type":"markdown","source":"Train on the picture on the [color image #124084](https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300/html/dataset/images/color/124084.html) from [Berkeley Segmentation Dataset and Benchmark repository](https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/).\n\n<img src=\"https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300/html/images/plain/normal/color/124084.jpg\"/>"},{"metadata":{"id":"77E7EBC9FB134B0EB9B045DB846A996E"},"cell_type":"markdown","source":"## Utils"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"181C579361B5487A9A4872AB24C68BC7"},"cell_type":"code","source":"import org.apache.sanselan.color.ColorConversions._","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.sanselan.color.ColorConversions._\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":1}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"BACAFA6383D441B082B381A957BDDC99"},"cell_type":"code","source":"def toLUV(bni:java.awt.image.BufferedImage, x:Int, y:Int) = {\n  //val xyz = org.apache.commons.imaging.color.ColorConversions.convertRGBtoXYZ(bni.getRGB(x,y))\n  val xyz = convertRGBtoXYZ(bni.getRGB(x,y))\n  val luv = convertXYZtoCIELuv(xyz)\n  (x+1, y+1, luv.L, luv.u, luv.v)\n}\ndef toRGB(L:Double, u:Double, v:Double) = {\n  val xyz = convertCIELuvtoXYZ(L, u, v)\n  val rgb = convertXYZtoRGB(xyz)\n  rgb\n}","outputs":[{"name":"stdout","output_type":"stream","text":"toLUV: (bni: java.awt.image.BufferedImage, x: Int, y: Int)(Int, Int, Double, Double, Double)\ntoRGB: (L: Double, u: Double, v: Double)Int\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":2}]},{"metadata":{"id":"A0F0B604F7994E588B7428FBFA5D7E4E"},"cell_type":"markdown","source":"## Build data <small>(optional)</small>"},{"metadata":{"id":"5E50B2BEBA6C4CB8ABE1D600CCDB0E51"},"cell_type":"markdown","source":"The data has to be given to the model training in _Luv_ colorspace, an usual way to represent the data then is CSV where the columns are $X$, $Y$, $L$, $u$, $v$."},{"metadata":{"id":"0FECA1FB4E994E64890E5992A81692A5"},"cell_type":"markdown","source":"In the current section, we'll take a picture and transform it in CSV in case we don't have it yet..."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"7F35A36C2A1443848C2B7E341BC7FD1A"},"cell_type":"code","source":"val imgpath = \"/root/data/coliseum/124084-orig.jpg\"","outputs":[{"name":"stdout","output_type":"stream","text":"imgpath: String = /root/data/coliseum/124084-orig.jpg\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":3}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"663D86D7FF164DC7833801D49DDB5820"},"cell_type":"code","source":"val bni = javax.imageio.ImageIO.read(new File(imgpath))","outputs":[{"name":"stdout","output_type":"stream","text":"bni: java.awt.image.BufferedImage = BufferedImage@5af4b117: type = 5 ColorModel: #pixelBits = 24 numComponents = 3 color space = java.awt.color.ICC_ColorSpace@5cf33e85 transparency = 1 has alpha = false isAlphaPre = false ByteInterleavedRaster: width = 481 height = 321 #numDataElements 3 dataOff[0] = 2\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":4}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"D65BF716451D40CF9010B9D3F094C314"},"cell_type":"code","source":"val h = bni.getHeight\nval w = bni.getWidth","outputs":[{"name":"stdout","output_type":"stream","text":"h: Int = 321\nw: Int = 481\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":5}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"95DCC9B4242441D687ED7CD609246EB9"},"cell_type":"code","source":"val luvs = for {\n  r <- 0 until h\n  c <- 0 until w\n} yield toLUV(bni, c, r)","outputs":[{"name":"stdout","output_type":"stream","text":"luvs: scala.collection.immutable.IndexedSeq[(Int, Int, Double, Double, Double)] = Vector((1,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (2,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (3,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (4,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (5,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (6,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (7,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (8,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (9,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (10,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (11,1,3.5595796218256233,-0.89784549889479,0.8906243600421717), (12,1,3.55957..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":6}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"717D6456E89F46F8B62DA04E1A1404FC"},"cell_type":"code","source":"val outputCSV = new File(\"/root/data/coliseum/output/124084-luv.jpg.csv\")\nif (outputCSV.exists) outputCSV.delete","outputs":[{"name":"stdout","output_type":"stream","text":"outputCSV: java.io.File = /root/data/coliseum/output/124084-luv.jpg.csv\nres8: AnyVal = ()\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":7}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"D8DBCFFF12EB4A8AB6F98847B19F7E0D"},"cell_type":"code","source":"val writer = new java.io.FileWriter(outputCSV)\nwriter.write(\"\"\" \"x\",\"y\",\"L\",\"u\",\"v\" \"\"\".trim)\nluvs.foreach { case (x, y, l, u, v) =>\n  writer.write(s\"\\n$x,$y,$l,$u,$v\")\n}\nwriter.flush\nwriter.close","outputs":[{"name":"stdout","output_type":"stream","text":"java.io.FileNotFoundException: /root/data/coliseum/output/124084-luv.jpg.csv (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:162)\n\tat java.io.FileWriter.<init>(FileWriter.java:90)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:74)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:93)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:95)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:97)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:99)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:101)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:103)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:105)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:107)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:109)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:111)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:113)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:115)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:117)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:119)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:121)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:123)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:125)\n\tat $iwC$$iwC$$iwC$$iwC.<init>(<console>:127)\n\tat $iwC$$iwC$$iwC.<init>(<console>:129)\n\tat $iwC$$iwC.<init>(<console>:131)\n\tat $iwC.<init>(<console>:133)\n\tat <init>(<console>:135)\n\tat .<init>(<console>:139)\n\tat .<clinit>(<console>)\n\tat .<init>(<console>:7)\n\tat .<clinit>(<console>)\n\tat $print(<console>)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:202)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:202)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat scala.Console$.withOut(Console.scala:126)\n\tat notebook.kernel.Repl.evaluate(Repl.scala:201)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.replEvaluate$1(ReplCalculator.scala:401)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:414)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:395)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n\n"}]},{"metadata":{"id":"523552796BF4454B8A7AE0F5B57A440B"},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"id":"FFDBB07BFC5042BAA09BA932F1E1534B"},"cell_type":"markdown","source":"Import model instance from Mean Shift LSH package"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2CD1660329D3459AA6A1F460F526E8A0"},"cell_type":"code","source":"val defp = sparkContext.defaultParallelism\nval meanShift = msLsh.MsLsh","outputs":[{"name":"stdout","output_type":"stream","text":"defp: Int = 4\nmeanShift: msLsh.MsLsh.type = msLsh.MsLsh$@7b5d30b4\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":9}]},{"metadata":{"id":"5AC52214318B42E680DDEFCBA80250F2"},"cell_type":"markdown","source":"Read the input data"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2DFED1EC049C4E448242E4DAA554953F"},"cell_type":"code","source":"val data = sc.textFile(\"/root/data/coliseum/124084-luv.csv\", defp)","outputs":[{"name":"stdout","output_type":"stream","text":"data: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at <console>:62\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":10}]},{"metadata":{"id":"5D43FDA739CD4EE6B2E6CE42FAC976D3"},"cell_type":"markdown","source":"Parse the lines, excluding the header and mapping to _mllib_ package"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"FA3F7315EA544FC982FB8ABAB2768B74"},"cell_type":"code","source":"val parsedData = data.filter(!_.startsWith(\"\\\"\")).map(x => x.split(','))\n                     .map(y => org.apache.spark.mllib.linalg.Vectors.dense(y.map(_.toDouble)))\n                     .zipWithIndex.map(_.swap)\n                     .map(x => (x._1.toString, x._2)).cache","outputs":[{"name":"stdout","output_type":"stream","text":"parsedData: org.apache.spark.rdd.RDD[(String, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[7] at map at <console>:67\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":11}]},{"metadata":{"id":"5F6899541A9E4BFA8D865D1700DB3722"},"cell_type":"markdown","source":"Creating SQL tools to allow DataFrame usage which will ease quick exploration."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0EDDEECCF3A6430498B5359548AFF624"},"cell_type":"code","source":"val sqlc = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlc.implicits._","outputs":[{"name":"stdout","output_type":"stream","text":"sqlc: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@441c12a7\nimport sqlc.implicits._\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":12}]},{"metadata":{"id":"5D3BB8DAA05A4F78BCBB5D042BC0D0C8"},"cell_type":"markdown","source":"Taking a look to the data"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"E77754F4948E418180CDE925893AFF8F"},"cell_type":"code","source":"parsedData.toDF","outputs":[]},{"metadata":{"id":"A6F20DD554F64F29B7140896785BD031"},"cell_type":"markdown","source":"### Training the model"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"7DFA71ADF24645BE84F35C312F7FEDF9"},"cell_type":"code","source":"var model:msLsh.mean_shift_lsh_model = null","outputs":[{"name":"stdout","output_type":"stream","text":"model: msLsh.mean_shift_lsh_model = null\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":13}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"0BCAB11EADA84E689AD820ED34F1318A"},"cell_type":"code","source":"val logTrain = out\nlogTrain","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"F03412F67D2F47BF9CA6008D27B5BC7F"},"cell_type":"code","source":"Form[Map[String,String]](\n  d = Map(\n    \"k\" -> \"60\",\n    \"threshold_cluster1\" -> \"0.05\",\n    \"threshold_cluster2\" -> \"0.05\",\n    \"yStarIter\" -> \"10\",\n    \"cmin\" -> \"0\",\n    \"normalisation\" -> \"true\",\n    \"w\" -> \"1\",\n    \"nbseg\" -> \"100\",\n    \"nbblocs1\" -> \"50\",\n    \"nbblocs2\" -> \"4\",\n    \"nbLabelIter\" -> \"1\"\n  ), \n  mainTitle = \"Tune the model\", \n  paramsToData = identity[Map[String,String]], \n  dataToParams = identity[Map[String,String]]\n) { map =>\n  logTrain(\"Starting Model Training\")\n  model = meanShift.train(sparkContext,\n                            parsedData,\n                            map(\"k\").toInt,\n                            map(\"threshold_cluster1\").toDouble,\n                            map(\"threshold_cluster2\").toDouble,\n                            map(\"yStarIter\").toInt,\n                            map(\"cmin\").toInt,\n                            map(\"normalisation\").toBoolean,\n                            map(\"w\").toInt,\n                            map(\"nbseg\").toInt,\n                            map(\"nbblocs1\").toInt,\n                            map(\"nbblocs2\").toInt,\n                            map(\"nbLabelIter\").toInt,\n                            nbPart=defp\n                          )\n  logTrain(\"Model trained\")\n}","outputs":[]},{"metadata":{"id":"9D93E4989A0C4D6988CB2EC3E119EEB5"},"cell_type":"markdown","source":"Save result for an image as `(ID, Vector, ClusterNumber)`"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"05F298A3A56B4057AA2DC835C10DA548"},"cell_type":"code","source":"val imageResultPath = \"/root/data/coliseum/output/MyImageResultDirectory\"","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"006C9B792A1C45BCBF71787290833C1A"},"cell_type":"code","source":":sh rm -rf $imageResultPath","outputs":[]},{"metadata":{"id":"C6AA8685036B4077AAE5B8CE13E0E3CE"},"cell_type":"markdown","source":"Save result as `(ID, ClusterNumber)`"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"9F4361C151AE441A9E58F50698889601"},"cell_type":"code","source":"val resultDirPath = \"/root/data/coliseum/output/MyResultDirectory\"","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"94B903E6D54340158F4790457AD85918"},"cell_type":"code","source":":sh rm -rf $resultDirPath ","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"811999536B594829A0D8B94633120091"},"cell_type":"code","source":"meanShift.savelabeling(model, resultDirPath, 1)","outputs":[]},{"metadata":{"id":"1AD12FA2A56F419482773192F8FAB395"},"cell_type":"markdown","source":"Save centroids result as `(NumCluster, cardinality, CentroidVector)`"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"C11E5610C37042418035E3F5ED71A8EA"},"cell_type":"code","source":"val centroidDirPath = \"/root/data/coliseum/output/centroidDirectory\"","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"D5BC944A011748F2BC9C4D45BBDAB437"},"cell_type":"code","source":":sh rm -rf $centroidDirPath","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"72739559D66142618175FE0579C61CC1"},"cell_type":"code","source":"meanShift.saveClusterInfo(sparkContext, model, centroidDirPath)","outputs":[]},{"metadata":{"id":"74B7BFA98AB04A93986E3D7EAE2CAACD"},"cell_type":"markdown","source":"# Read Model Info"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"B1530C4E04E64062A86A97D26C8F8C6C"},"cell_type":"code","source":"val resultImage = sparkContext.textFile(imageResultPath)","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"F0DC0A6BE8804CBE8965CF3316897322"},"cell_type":"code","source":"val parsed = resultImage.map { s =>\n  val l = s.split(\",\").toList.map(_.replaceAll(\"[\\\\[\\\\]\\\\(\\\\)]\", \"\"))\n  val id = l.head.toInt\n  val centroid = org.apache.spark.mllib.linalg.Vectors.dense(l.tail.init.map(_.toDouble).toArray)\n  val cluster = l.last.toInt\n  (id, centroid, cluster)\n}","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"BAE857AA59F5410881C8068F01AA57C0"},"cell_type":"code","source":"val parsedDf = parsed.toDF","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"F8F0FCD397814AF28F38672606E1D82A"},"cell_type":"code","source":"val resArr = parsedDf.select(\"_2\").map(_.getAs[org.apache.spark.mllib.linalg.Vector](0)).map(_.toArray.toList).collect\nval resList = resArr.toList","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"3C01A0A3F16E42EC93CF94D87DEA3878"},"cell_type":"code","source":"import java.awt.image.BufferedImage\nval resImg = new BufferedImage(h, w, BufferedImage.TYPE_INT_RGB)\nval rbgs:Array[Int] = resArr.map{ case List(_, _, l, u, v) => toRGB(l, u, v) }.toArray\nresImg.setRGB(0, 0, h, w, rbgs, 0, h)\nval ii = img(\"jpg\", h+\"px\", w+\"px\")\nii(resImg)\nii","outputs":[]}],"nbformat":4}